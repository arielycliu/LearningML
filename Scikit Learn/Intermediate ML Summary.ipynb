{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67d1076",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "Dealing with missing values with imputation and imputation with extra column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dc4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "house = pd.read_csv(\"melb_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d35a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c4aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house.drop(['Price'], axis=1)\n",
    "X_m = X.select_dtypes(exclude=['object']) # remove categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50340fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0      2       2.5    3067.0       2.0       1.0  1.0     202.0           NaN   \n",
       "1      2       2.5    3067.0       2.0       1.0  0.0     156.0          79.0   \n",
       "2      3       2.5    3067.0       3.0       2.0  0.0     134.0         150.0   \n",
       "3      3       2.5    3067.0       3.0       2.0  1.0      94.0           NaN   \n",
       "4      4       2.5    3067.0       3.0       1.0  2.0     120.0         142.0   \n",
       "\n",
       "   YearBuilt  Lattitude  Longtitude  Propertycount  \n",
       "0        NaN   -37.7996    144.9984         4019.0  \n",
       "1     1900.0   -37.8079    144.9934         4019.0  \n",
       "2     1900.0   -37.8093    144.9944         4019.0  \n",
       "3        NaN   -37.7969    144.9969         4019.0  \n",
       "4     2014.0   -37.8072    144.9941         4019.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_m.head()# we can see that there are missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31238a",
   "metadata": {},
   "source": [
    "### Method 1. Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4ab543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import that stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85e60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_m, y, random_state=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da128835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.copy()\n",
    "X_test1 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164920bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify which columns are missing values\n",
    "missing = [c for c in X_train1.columns if X_train1[c].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6877c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train1.drop(missing, axis=1) # drop the columns\n",
    "X_test1 = X_test1.drop(missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b84e315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this into one function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def check_model(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(predictions, y_test)\n",
    "    print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eff0bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183809.3433827232\n"
     ]
    }
   ],
   "source": [
    "check_model(X_train1, X_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf9ebc",
   "metadata": {},
   "source": [
    "### Method 2. Imputation with the new column\n",
    "Have a new column like bed_val_was_missing to indicate that the value was filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8108c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "669d6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new columns\n",
    "for c in missing: # loop thru each column with missing values\n",
    "    X_train2[c + '_was_missing'] = X_train2[c].isnull()  # isnull returns a list of boolean\n",
    "    X_test2[c + '_was_missing'] = X_test2[c].isnull()\n",
    "    # so you create a new column for each feature with missing values that tells you if the value was missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a891a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer()\n",
    "\n",
    "X_train2 = pd.DataFrame(imp.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(imp.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55b679a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the column names back\n",
    "X_train2.columns = X_train.columns\n",
    "X_test2.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00fb2987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181323.49856605186\n"
     ]
    }
   ],
   "source": [
    "check_model(X_train2, X_test2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ca0d78b",
   "metadata": {},
   "source": [
    "Slightly better than the method of dropping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb17a2",
   "metadata": {},
   "source": [
    "# Categorical Variables\n",
    "One hot encoding and ordinal encoding\n",
    "Make sure to use the X1 we made from before that doesn't have any missing values cause we dropped them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a094eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with missing values so that we can build model and focus on testing stuff with categorical variables instead\n",
    "missing = [c for c in X.columns if X[c].isnull().any()]\n",
    "X_C = X.drop(missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7671bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it up\n",
    "X_trainC, X_testC, y_trainC, y_testC = train_test_split(X_C, y, random_state=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d108173",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (X_trainC.dtypes == 'object')\n",
    "obj_columns = list(s[s].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482dcad",
   "metadata": {},
   "source": [
    "### Method 1. Drop the Categorical Variables\n",
    "drop the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb832f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainC1 = X_trainC.copy()\n",
    "X_testC1 = X_testC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f17e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_trainC = X_trainC.drop(obj_columns, axis=1) # drop using the list we made before, doesn't work cause test and train different lists would need to make 2 lists\n",
    "\n",
    "X_trainC1 = X_trainC1.select_dtypes(exclude=['object'])\n",
    "X_testC1 = X_testC1.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcacf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183998.72946118476\n"
     ]
    }
   ],
   "source": [
    "check_model(X_trainC1, X_testC1, y_trainC, y_testC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac63b1",
   "metadata": {},
   "source": [
    "### Method 2. Ordinal Encoding\n",
    "Encoding the text into numbers, doesn't really work here since there is no order of better home addresses but whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eba3d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainC2 = X_trainC.copy()\n",
    "X_testC2 = X_testC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97f8d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['Type', 'Method', 'Date', 'Regionname']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Address', 'SellerG', 'Suburb']\n"
     ]
    }
   ],
   "source": [
    "# Fitting an ordinal encoder to a column in the training data creates a corresponding integer-valued label for each unique value that appears in the training data. \n",
    "# In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them\n",
    "\n",
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_trainC2.columns if X_trainC2[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_testC2[col]).issubset(set(X_trainC2[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd292244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Method', 'SellerG', 'Date',\n",
       "       'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Landsize', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainC2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b43155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "X_trainC2[good_label_cols] = encoder.fit_transform(X_trainC2[good_label_cols])\n",
    "X_testC2[good_label_cols] = encoder.transform(X_testC2[good_label_cols])\n",
    "\n",
    "# Drop bad columns\n",
    "X_trainC2 = X_trainC2.drop(bad_label_cols, axis=1)\n",
    "X_testC2 = X_testC2.drop(bad_label_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b190e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174683.60445360825\n"
     ]
    }
   ],
   "source": [
    "check_model(X_trainC2, X_testC2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba62869",
   "metadata": {},
   "source": [
    "### Method 3. One-Hot Encoding\n",
    "Adding a lot of new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6dd9215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainC3 = X_trainC.copy()\n",
    "X_testC3 = X_testC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f38e46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False) # set handle_unknown to ignore to avoid error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17da92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_trainC.columns if X_trainC[col].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ecfe7375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['Type', 'Method', 'Regionname']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Date', 'Address', 'SellerG', 'Suburb']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_trainC3[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c339f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NEW datafram with onehot encoded columns from the low cardinality ones only\n",
    "OH_X_trainC3 = pd.DataFrame(OH_encoder.fit_transform(X_trainC[low_cardinality_cols]))\n",
    "OH_X_testC3 = pd.DataFrame(OH_encoder.transform(X_testC[low_cardinality_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff24a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the index back\n",
    "OH_X_trainC3.index = X_trainC.index\n",
    "OH_X_testC3.index = X_testC.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e8a605f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old categorical columns from the whole dataset\n",
    "# This is the numerical data\n",
    "numerical_X_trainC3 = X_trainC.drop(object_cols, axis=1)\n",
    "numerical_X_testC3 = X_testC.drop(object_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6efae00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainC3N = pd.concat([numerical_X_trainC3, OH_X_trainC3], axis=1) # join the numerical data together with the onehot encoded dataframe\n",
    "X_testC3N = pd.concat([numerical_X_testC3, OH_X_testC3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc1e3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174218.45805161653\n"
     ]
    }
   ],
   "source": [
    "check_model(X_trainC3N, X_testC3N, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7a90d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=500) # higher since early stopping\n",
    "model.fit(X_trainC3N, y_train, early_stopping_rounds=5, eval_set=[(X_testC3N, y_test)], verbose=False) # can also set to true for text progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59965e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_testC3N)\n",
    "mae = mean_absolute_error(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbf69f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171101.31754418262"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b45e7c08",
   "metadata": {},
   "source": [
    "Lowest MAE yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
